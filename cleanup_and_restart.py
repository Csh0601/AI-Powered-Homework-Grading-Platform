#!/usr/bin/env python3
"""
æ•°æ®æ”¶é›†ç³»ç»Ÿé‡ç½®è„šæœ¬
æ¸…é™¤æ‰€æœ‰ç°æœ‰æ•°æ®å¹¶é‡æ–°å¼€å§‹æ”¶é›†
"""

import os
import shutil
import sqlite3
from pathlib import Path

def cleanup_all_data():
    """æ¸…é™¤æ‰€æœ‰æ•°æ®å¹¶é‡ç½®ç³»ç»Ÿ"""
    print("ğŸ§¹ å¼€å§‹å…¨é¢æ•°æ®æ¸…ç†...")

    # 1. æ¸…é™¤åŸå§‹æ•°æ®ç›®å½•
    raw_dir = Path("raw")
    if raw_dir.exists():
        shutil.rmtree(raw_dir)
        print("âœ… å·²åˆ é™¤ raw/ ç›®å½•")

    # 2. æ¸…é™¤å¤„ç†åçš„æ•°æ®
    processed_dir = Path("processed")
    if processed_dir.exists():
        shutil.rmtree(processed_dir)
        print("âœ… å·²åˆ é™¤ processed/ ç›®å½•")

    # 3. æ¸…é™¤çˆ¬è™«æ•°æ®
    crawled_data_dir = Path("collectors/crawled_data")
    if crawled_data_dir.exists():
        # ä¿ç•™ç›®å½•æœ¬èº«ï¼Œä½†åˆ é™¤å†…å®¹
        for item in crawled_data_dir.iterdir():
            if item.is_file():
                item.unlink()
            elif item.is_dir():
                shutil.rmtree(item)
        print("âœ… å·²æ¸…ç©º collectors/crawled_data/ ç›®å½•")

    # 4. æ¸…é™¤è´¨é‡ç§å­æ•°æ®
    quality_dir = Path("quality_seed_data")
    if quality_dir.exists():
        shutil.rmtree(quality_dir)
        print("âœ… å·²åˆ é™¤ quality_seed_data/ ç›®å½•")

    # 5. æ¸…ç©ºæ•°æ®åº“
    db_paths = [
        "llmhomework_Backend/database/knowledge_base.db",
        "collectors/crawled_data/crawl_progress.db"
    ]

    for db_path in db_paths:
        if os.path.exists(db_path):
            try:
                os.remove(db_path)
                print(f"âœ… å·²åˆ é™¤æ•°æ®åº“: {db_path}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æ•°æ®åº“å¤±è´¥ {db_path}: {e}")

    # 6. æ¸…é™¤ç¼“å­˜æ–‡ä»¶
    cache_files = [
        "collectors/generated_cache.json",
        "collectors/crawled_data/crawl_metadata_*.json"
    ]

    for cache_pattern in cache_files:
        if "*" in cache_pattern:
            # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
            pattern_path = Path(cache_pattern.replace("*", ""))
            if pattern_path.exists():
                for file in pattern_path.parent.glob(cache_pattern.replace("*", "*")):
                    try:
                        file.unlink()
                        print(f"âœ… å·²åˆ é™¤ç¼“å­˜æ–‡ä»¶: {file}")
                    except Exception as e:
                        print(f"âš ï¸ åˆ é™¤ç¼“å­˜å¤±è´¥ {file}: {e}")
        else:
            cache_path = Path(cache_pattern)
            if cache_path.exists():
                cache_path.unlink()
                print(f"âœ… å·²åˆ é™¤ç¼“å­˜æ–‡ä»¶: {cache_path}")

    # 7. æ¸…é™¤ä¸´æ—¶æ–‡ä»¶
    temp_files = ["check_db_final.py", "analyze_website.py", "analyze_chinese_page.py"]
    for temp_file in temp_files:
        temp_path = Path(temp_file)
        if temp_path.exists():
            temp_path.unlink()
            print(f"âœ… å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file}")

    print("\nğŸ‰ æ•°æ®æ¸…ç†å®Œæˆ!")
    print("ç³»ç»Ÿå·²é‡ç½®ï¼Œå¯ä»¥é‡æ–°å¼€å§‹æ•°æ®æ”¶é›†")

def show_cleanup_summary():
    """æ˜¾ç¤ºæ¸…ç†åçš„çŠ¶æ€"""
    print("\nğŸ“Š æ¸…ç†åçš„ç³»ç»ŸçŠ¶æ€:")

    # æ£€æŸ¥ä¸»è¦ç›®å½•
    directories = ["raw", "processed", "collectors/crawled_data", "quality_seed_data"]
    for dir_path in directories:
        path = Path(dir_path)
        if path.exists():
            item_count = len(list(path.rglob("*")))
            print(f"  {dir_path}: {item_count} é¡¹")
        else:
            print(f"  {dir_path}: ä¸å­˜åœ¨")

    # æ£€æŸ¥æ•°æ®åº“
    db_paths = ["llmhomework_Backend/database/knowledge_base.db", "collectors/crawled_data/crawl_progress.db"]
    for db_path in db_paths:
        if os.path.exists(db_path):
            print(f"  {db_path}: å­˜åœ¨")
        else:
            print(f"  {db_path}: ä¸å­˜åœ¨")

if __name__ == "__main__":
    cleanup_all_data()
    show_cleanup_summary()

