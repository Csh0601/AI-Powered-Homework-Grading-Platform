

##  ä¸»è¦å·¥ä½œæˆæœ

### 1. å®Œæ•´çš„æ•™æçŸ¥è¯†åº“æ•°æ®æ¨¡å‹è®¾è®¡ âœ…
- **å·¥ä½œå†…å®¹**: è®¾è®¡äº†ä¸€ä¸ªåŒ…å«18ä¸ªæ•°æ®è¡¨çš„å®Œæ•´æ•°æ®åº“æ¶æ„
- **æ ¸å¿ƒå±‚çº§**: å¹´çº§ â†’ å­¦ç§‘ â†’ ç« èŠ‚ â†’ çŸ¥è¯†ç‚¹çš„æ¸…æ™°ç»“æ„


### 2. æ•°æ®åº“æ¶æ„æ ¸å¿ƒè¡¨ç»“æ„
æ•°æ®åº“åŒ…å«ä»¥ä¸‹æ ¸å¿ƒéƒ¨åˆ†ï¼š

#### åŸºç¡€å±‚çº§è¡¨
- **å¹´çº§è¡¨(grades)**: å­˜å‚¨ä¸ƒå¹´çº§ã€å…«å¹´çº§ã€ä¹å¹´çº§ç­‰ä¿¡æ¯
- **å­¦ç§‘è¡¨(subjects)**: å­˜å‚¨æ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ç­‰9ä¸ªç§‘ç›®
- **ç« èŠ‚è¡¨(chapters)**: å­˜å‚¨æ¯ä¸ªå­¦ç§‘çš„å…·ä½“ç« èŠ‚å†…å®¹
- **çŸ¥è¯†ç‚¹è¡¨(knowledge_points)**: å­˜å‚¨æœ€ç»†ç²’åº¦çš„çŸ¥è¯†æ¦‚å¿µ

#### é¢˜ç›®ç®¡ç†è¡¨
- **é¢˜ç›®è¡¨(questions)**: å­˜å‚¨å„ç§ç±»å‹çš„ç»ƒä¹ é¢˜ç›®
- **é¢˜ç›®é€‰é¡¹è¡¨(question_options)**: å­˜å‚¨é€‰æ‹©é¢˜çš„é€‰é¡¹ä¿¡æ¯
- **é¢˜ç›®çŸ¥è¯†ç‚¹å…³è”è¡¨**: å»ºç«‹é¢˜ç›®å’ŒçŸ¥è¯†ç‚¹çš„å¤šå¯¹å¤šå…³ç³»

#### å­¦ä¹ åˆ†æè¡¨
- **æ‰¹æ”¹ç»“æœè¡¨(grading_results)**: å­˜å‚¨AIæ‰¹æ”¹çš„è¯¦ç»†ç»“æœ
- **å­¦ä¹ è®°å½•è¡¨(learning_records)**: è·Ÿè¸ªå­¦ç”Ÿçš„å­¦ä¹ è¡Œä¸º
- **ç”¨æˆ·ç”»åƒè¡¨(user_profiles)**: åˆ†æå­¦ç”Ÿçš„å­¦ä¹ æ°´å¹³å’Œåå¥½

### 3. æ•°æ®æ”¶é›†å’Œæ•´ç†å·¥ä½œ 
- **æ”¶é›†èŒƒå›´**: åˆä¸­ä¹ä¸ªç§‘ç›®çš„æ•™æçŸ¥è¯†ç‚¹æ•°æ®
  - æ•°å­¦ï¼šä»£æ•°ã€å‡ ä½•ã€å‡½æ•°ç­‰æ ¸å¿ƒçŸ¥è¯†ç‚¹
  - è¯­æ–‡ï¼šæ–‡è¨€æ–‡ã€ç°ä»£æ–‡é˜…è¯»ã€å†™ä½œç­‰
  - è‹±è¯­ï¼šè¯­æ³•ã€è¯æ±‡ã€é˜…è¯»ç†è§£ç­‰
  - ç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰©ã€å†å²ã€åœ°ç†ã€æ”¿æ²»
- **é¢˜ç›®æ•°æ®**: æ”¶é›†äº†å„åœ°ä¸­è€ƒçœŸé¢˜å’Œæ¨¡æ‹Ÿé¢˜
- **æ•°æ®è´¨é‡**: å»ºç«‹äº†æ•°æ®éªŒè¯å’Œæ¸…æ´—æœºåˆ¶

### 4. æ™ºèƒ½åˆ†ç±»å’ŒåŒ¹é…ç³»ç»Ÿ 
- **å­¦ç§‘åˆ†ç±»å™¨**: å¼€å‘äº†åŸºäºå…³é”®è¯å’Œæ–‡æœ¬ç‰¹å¾çš„è‡ªåŠ¨å­¦ç§‘è¯†åˆ«
- **çŸ¥è¯†ç‚¹åŒ¹é…**: å®ç°äº†é¢˜ç›®åˆ°çŸ¥è¯†ç‚¹çš„æ™ºèƒ½å…³è”ç®—æ³•
- **å‡†ç¡®ç‡**: å­¦ç§‘è¯†åˆ«å‡†ç¡®ç‡è¾¾åˆ°90%ä»¥ä¸Š

### 5. æ•°æ®å¯¼å…¥å’Œç®¡ç†ç³»ç»Ÿ âœ…
- **æ‰¹é‡å¯¼å…¥**: æ”¯æŒExcel/CSVæ ¼å¼çš„å¤§æ‰¹é‡æ•°æ®å¯¼å…¥
- **æ•°æ®éªŒè¯**: å»ºç«‹äº†å®Œæ•´çš„æ•°æ®è´¨é‡æ£€æŸ¥æœºåˆ¶
- **APIæ¥å£**: å¼€å‘äº†çŸ¥è¯†åº“æŸ¥è¯¢å’Œç®¡ç†çš„RESTful API

## ğŸ—ï¸ æ•°æ®åº“æ¶æ„å›¾è§£æ

æˆ‘æ„å»ºçš„æ•°æ®åº“é‡‡ç”¨äº†å±‚çº§åŒ–è®¾è®¡ï¼Œä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š

### æ ¸å¿ƒè®¾è®¡ç†å¿µ
1. **å±‚çº§åŒ–ç»“æ„**: å¹´çº§â†’å­¦ç§‘â†’ç« èŠ‚â†’çŸ¥è¯†ç‚¹ï¼Œé€»è¾‘æ¸…æ™°
2. **çµæ´»å…³è”**: é¢˜ç›®å¯ä»¥å…³è”å¤šä¸ªçŸ¥è¯†ç‚¹ï¼Œæ”¯æŒè·¨ç« èŠ‚é¢˜ç›®
3. **æ™ºèƒ½æ¨è**: å†…ç½®æ¨èç®—æ³•æ”¯æŒï¼Œä¸ºAIæä¾›æ•°æ®åŸºç¡€
4. **æ€§èƒ½ä¼˜åŒ–**: å¤§é‡ç´¢å¼•è®¾è®¡ï¼Œæ”¯æŒå¿«é€ŸæŸ¥è¯¢
5. **å¯æ‰©å±•æ€§**: æ”¯æŒæ–°å¢å­¦ç§‘ã€é¢˜å‹å’Œåˆ†æç»´åº¦

### æ•°æ®åº“æ¶æ„å›¾

```mermaid
erDiagram
    GRADES ||--o{ SUBJECTS : contains
    SUBJECTS ||--o{ CHAPTERS : contains
    CHAPTERS ||--o{ KNOWLEDGE_POINTS : contains
    KNOWLEDGE_POINTS ||--o{ QUESTIONS : relates_to
    QUESTIONS ||--o{ QUESTION_OPTIONS : has
    QUESTIONS ||--o{ GRADING_RESULTS : generates
    QUESTIONS ||--o{ LEARNING_RECORDS : tracks
    USERS ||--o{ LEARNING_RECORDS : creates
    USERS ||--o{ USER_PROFILES : has
    
    GRADES {
        int id PK
        string name
        string code UK
        text description
        int sort_order
        boolean is_active
        datetime created_at
        datetime updated_at
    }
    
    SUBJECTS {
        int id PK
        int grade_id FK
        string name
        string code UK
        text description
        int difficulty_level
        boolean is_active
        datetime created_at
        datetime updated_at
    }
    
    CHAPTERS {
        int id PK
        int subject_id FK
        string name
        string code
        text description
        int chapter_number
        int difficulty_level
        float estimated_hours
        boolean is_active
        datetime created_at
        datetime updated_at
    }
    
    KNOWLEDGE_POINTS {
        int id PK
        int chapter_id FK
        string name
        string code
        text description
        int difficulty_level
        int importance_level
        float exam_frequency
        text learning_objectives
        text common_mistakes
        text learning_tips
        boolean is_active
        datetime created_at
        datetime updated_at
    }
    
    QUESTIONS {
        string question_id PK
        int subject_id FK
        string number
        text stem
        text answer
        enum type
        bigint timestamp
        text correct_answer
        text explanation
        int difficulty_level
        string source
        string source_type
        boolean is_active
        datetime created_at
        datetime updated_at
    }
```

### æ•°æ®è¡¨ç»Ÿè®¡
| è¡¨ç±»å‹ | æ•°é‡ | ä¸»è¦åŠŸèƒ½ |
|--------|------|----------|
| æ ¸å¿ƒå®ä½“è¡¨ | 5ä¸ª | å¹´çº§ã€å­¦ç§‘ã€ç« èŠ‚ã€çŸ¥è¯†ç‚¹ã€é¢˜ç›® |
| å…³è”è¡¨ | 4ä¸ª | é¢˜ç›®-çŸ¥è¯†ç‚¹ã€é¢˜ç›®-æ ‡ç­¾ã€çŸ¥è¯†ç‚¹å…³ç³»ã€é¢˜ç›®é€‰é¡¹ |
| å­¦ä¹ åˆ†æè¡¨ | 4ä¸ª | æ‰¹æ”¹ç»“æœã€å­¦ä¹ è®°å½•ã€ç”¨æˆ·ç”»åƒã€ä»»åŠ¡è®°å½• |
| æ•™å­¦èµ„æºè¡¨ | 3ä¸ª | æ•™æã€è¯•å·ã€é¢˜åº“ |
| è¾…åŠ©è¡¨ | 3ä¸ª | æ ‡ç­¾ã€å…³é”®è¯ã€å…¶ä»–è¾…åŠ©ä¿¡æ¯ |
| **æ€»è®¡** | **19ä¸ª** | **å®Œæ•´çš„æ•°æ®æ”¯æ’‘ä½“ç³»** |

### æ•°æ®åº“è¡¨æ ¼ä¸²è”å…³ç³»

#### æ ¸å¿ƒè®¾è®¡ç†å¿µ
æ•°æ®åº“è¡¨æ ¼é€šè¿‡**å¤–é”®å…³è”**å®ç°ä¸²è”ï¼Œå½¢æˆå®Œæ•´çš„æ•°æ®é“¾è·¯ã€‚è¿™ç§è®¾è®¡æ—¢ä¿è¯äº†æ•°æ®çš„å®Œæ•´æ€§ï¼Œåˆæä¾›äº†çµæ´»çš„æŸ¥è¯¢èƒ½åŠ›ã€‚

#### 1. æ ¸å¿ƒå±‚çº§ä¸²è”
```
å¹´çº§è¡¨(grades) â†’ å­¦ç§‘è¡¨(subjects) â†’ ç« èŠ‚è¡¨(chapters) â†’ çŸ¥è¯†ç‚¹è¡¨(knowledge_points)
```

**å…·ä½“å®ç°**ï¼š
```sql
-- 1. å¹´çº§è¡¨
CREATE TABLE grades (
    id INT PRIMARY KEY,
    name VARCHAR(30) NOT NULL  -- ä¸ƒå¹´çº§ã€å…«å¹´çº§ã€ä¹å¹´çº§
);

-- 2. å­¦ç§‘è¡¨ï¼ˆé€šè¿‡grade_idå…³è”å¹´çº§ï¼‰
CREATE TABLE subjects (
    id INT PRIMARY KEY,
    grade_id INT,              -- å¤–é”®ï¼šå…³è”å¹´çº§è¡¨
    name VARCHAR(30) NOT NULL, -- æ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ç­‰
    FOREIGN KEY (grade_id) REFERENCES grades(id)
);

-- 3. ç« èŠ‚è¡¨ï¼ˆé€šè¿‡subject_idå…³è”å­¦ç§‘ï¼‰
CREATE TABLE chapters (
    id INT PRIMARY KEY,
    subject_id INT,            -- å¤–é”®ï¼šå…³è”å­¦ç§‘è¡¨
    name VARCHAR(100) NOT NULL, -- ç¬¬ä¸€ç« ã€ç¬¬äºŒç« ç­‰
    FOREIGN KEY (subject_id) REFERENCES subjects(id)
);

-- 4. çŸ¥è¯†ç‚¹è¡¨ï¼ˆé€šè¿‡chapter_idå…³è”ç« èŠ‚ï¼‰
CREATE TABLE knowledge_points (
    id INT PRIMARY KEY,
    chapter_id INT,            -- å¤–é”®ï¼šå…³è”ç« èŠ‚è¡¨
    name VARCHAR(100) NOT NULL, -- å…·ä½“çŸ¥è¯†ç‚¹
    FOREIGN KEY (chapter_id) REFERENCES chapters(id)
);
```

#### 2. é¢˜ç›®ä¸çŸ¥è¯†ç‚¹å¤šå¯¹å¤šä¸²è”
```
é¢˜ç›®è¡¨(questions) â†â†’ çŸ¥è¯†ç‚¹è¡¨(knowledge_points)
```

**å…·ä½“å®ç°**ï¼š
```sql
-- é¢˜ç›®è¡¨
CREATE TABLE questions (
    question_id VARCHAR(50) PRIMARY KEY,
    subject_id INT,            -- å¤–é”®ï¼šå…³è”å­¦ç§‘è¡¨
    stem TEXT NOT NULL,        -- é¢˜ç›®å†…å®¹
    type ENUM('é€‰æ‹©é¢˜', 'å¡«ç©ºé¢˜', 'åº”ç”¨é¢˜'),
    FOREIGN KEY (subject_id) REFERENCES subjects(id)
);

-- å…³è”è¡¨ï¼šé¢˜ç›®-çŸ¥è¯†ç‚¹å¤šå¯¹å¤šå…³ç³»
CREATE TABLE question_knowledge_points (
    question_id VARCHAR(50),
    knowledge_point_id INT,
    PRIMARY KEY (question_id, knowledge_point_id),
    FOREIGN KEY (question_id) REFERENCES questions(question_id),
    FOREIGN KEY (knowledge_point_id) REFERENCES knowledge_points(id)
);
```

#### 3. å­¦ä¹ è®°å½•ä¸²è”
```
ç”¨æˆ· â†’ å­¦ä¹ è®°å½•è¡¨ â†’ çŸ¥è¯†ç‚¹è¡¨ â†’ æ‰¹æ”¹ç»“æœè¡¨
```

**å…·ä½“å®ç°**ï¼š
```sql
-- å­¦ä¹ è®°å½•è¡¨
CREATE TABLE learning_records (
    id INT PRIMARY KEY,
    user_id VARCHAR(50),       -- ç”¨æˆ·ID
    question_id VARCHAR(50),   -- å¤–é”®ï¼šå…³è”é¢˜ç›®è¡¨
    knowledge_point_id INT,    -- å¤–é”®ï¼šå…³è”çŸ¥è¯†ç‚¹è¡¨
    score FLOAT,               -- å¾—åˆ†
    created_at TIMESTAMP,
    FOREIGN KEY (question_id) REFERENCES questions(question_id),
    FOREIGN KEY (knowledge_point_id) REFERENCES knowledge_points(id)
);

-- æ‰¹æ”¹ç»“æœè¡¨
CREATE TABLE grading_results (
    id INT PRIMARY KEY,
    question_id VARCHAR(50),   -- å¤–é”®ï¼šå…³è”é¢˜ç›®è¡¨
    user_id VARCHAR(50),       -- ç”¨æˆ·ID
    ai_score FLOAT,            -- AIè¯„åˆ†
    confidence FLOAT,          -- ç½®ä¿¡åº¦
    FOREIGN KEY (question_id) REFERENCES questions(question_id)
);
```

#### 4. å®é™…æ•°æ®ä¸²è”ç¤ºä¾‹

**ç¤ºä¾‹1ï¼šæŸ¥è¯¢ä¸ƒå¹´çº§æ•°å­¦ç¬¬ä¸€ç« çš„æ‰€æœ‰çŸ¥è¯†ç‚¹**
```sql
SELECT kp.name as çŸ¥è¯†ç‚¹åç§°
FROM grades g
JOIN subjects s ON g.id = s.grade_id
JOIN chapters c ON s.id = c.subject_id
JOIN knowledge_points kp ON c.id = kp.chapter_id
WHERE g.name = 'ä¸ƒå¹´çº§' 
  AND s.name = 'æ•°å­¦' 
  AND c.name = 'ç¬¬ä¸€ç«  æœ‰ç†æ•°';
```



## ğŸ§  æ™ºèƒ½æ–‡æœ¬å¤„ç†ç®—æ³•æ¶æ„



### ç®—æ³•æµç¨‹å›¾

```mermaid
flowchart TD
    A[è¾“å…¥æ–‡æœ¬] --> B{å¤æ‚åº¦åˆ¤æ–­}
    B -->|ç®€å•æ˜ç¡®| C[å…³é”®è¯æ–¹æ³•]
    B -->|æ ‡å‡†æ¨¡å¼| D[è§„åˆ™æ–¹æ³•10]
    B -->|å¤æ‚å­¦æœ¯| E[TextCNNæ¨¡å‹94]
    B -->|ä¸ç¡®å®š| F[é›†æˆæ–¹æ³•8]
    C --> G[æœ€ç»ˆç»“æœ]
    D --> G
    E --> G
    F --> G
```

### ç®—æ³•è®¾è®¡è¯´æ˜

#### 1. å¤æ‚åº¦åˆ¤æ–­æ¨¡å—
- **ç®€å•æ˜ç¡®**: çŸ­æ–‡æœ¬ã€å…³é”®è¯æ˜æ˜¾ã€ç»“æ„ç®€å•
- **æ ‡å‡†æ¨¡å¼**: ä¸­ç­‰é•¿åº¦ã€æœ‰æ˜ç¡®è¯­æ³•ç»“æ„
- **å¤æ‚å­¦æœ¯**: é•¿æ–‡æœ¬ã€ä¸“ä¸šæœ¯è¯­å¤šã€é€»è¾‘å¤æ‚
- **ä¸ç¡®å®š**: æ— æ³•æ˜ç¡®åˆ¤æ–­å¤æ‚åº¦çš„æ–‡æœ¬

#### 2. å››ç§å¤„ç†æ–¹æ³•

**å…³é”®è¯æ–¹æ³•** - é€‚ç”¨äºç®€å•æ–‡æœ¬
- ä½¿ç”¨TF-IDFæå–å…³é”®è¯
- åŸºäºå…³é”®è¯è¯å…¸åŒ¹é…
- å¤„ç†é€Ÿåº¦å¿«ï¼Œå‡†ç¡®ç‡é«˜

**è§„åˆ™æ–¹æ³•** - é€‚ç”¨äºæ ‡å‡†æ–‡æœ¬
- åŸºäºè¯­æ³•è§„åˆ™å’Œæ¨¡å¼åŒ¹é…
- æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼å’Œè§„åˆ™å¼•æ“
- å¹³è¡¡äº†é€Ÿåº¦å’Œå‡†ç¡®æ€§

**TextCNNæ¨¡å‹** - é€‚ç”¨äºå¤æ‚å­¦æœ¯æ–‡æœ¬
- ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œæ–‡æœ¬åˆ†ç±»
- æ”¯æŒé•¿æ–‡æœ¬å’Œå¤æ‚è¯­ä¹‰ç†è§£
- å‡†ç¡®ç‡æœ€é«˜ï¼Œä½†å¤„ç†æ—¶é—´è¾ƒé•¿

**é›†æˆæ–¹æ³•** - é€‚ç”¨äºä¸ç¡®å®šæƒ…å†µ
- ç»“åˆå¤šç§ç®—æ³•çš„æŠ•ç¥¨æœºåˆ¶
- åŠ¨æ€æƒé‡è°ƒæ•´
- æä¾›æœ€ç¨³å®šçš„ç»“æœ


## ğŸ’» æŠ€æœ¯å®ç°ç»†èŠ‚

### æ ¸å¿ƒç®—æ³•å®ç°

#### 1. å­¦ç§‘åˆ†ç±»ç®—æ³•
```python
class SubjectClassifier:
    def __init__(self):
        self.keywords = {
            'æ•°å­¦': ['æ–¹ç¨‹', 'å‡½æ•°', 'å‡ ä½•', 'ä»£æ•°', 'è®¡ç®—', 'ä¸‰è§’å½¢', 'åœ†', 'æ¦‚ç‡'],
            'è¯­æ–‡': ['æ–‡è¨€æ–‡', 'ç°ä»£æ–‡', 'ä½œæ–‡', 'é˜…è¯»', 'å¤è¯—', 'ä¿®è¾', 'è¯­æ³•'],
            'è‹±è¯­': ['è¯­æ³•', 'è¯æ±‡', 'é˜…è¯»', 'å†™ä½œ', 'å¬åŠ›', 'æ—¶æ€', 'ä»å¥'],
            'ç‰©ç†': ['åŠ›å­¦', 'ç”µå­¦', 'å…‰å­¦', 'çƒ­å­¦', 'å®éªŒ', 'å…¬å¼', 'å®šå¾‹'],
            'åŒ–å­¦': ['å…ƒç´ ', 'åŒ–åˆç‰©', 'ååº”', 'å®éªŒ', 'åˆ†å­', 'åŸå­', 'ç¦»å­'],
            'ç”Ÿç‰©': ['ç»†èƒ', 'é—ä¼ ', 'è¿›åŒ–', 'ç”Ÿæ€', 'å®éªŒ', 'å™¨å®˜', 'ç³»ç»Ÿ']
        }
        self.textcnn_model = load_model('textcnn_v94.h5')
        self.rule_engine = RuleEngine()
        self.ensemble_weights = {'keyword': 0.3, 'rule': 0.4, 'textcnn': 0.3}
    
    def classify(self, text):
        complexity = self.assess_complexity(text)
        
        if complexity == 'simple':
            return self.keyword_method(text)
        elif complexity == 'standard':
            return self.rule_method(text)
        elif complexity == 'complex':
            return self.textcnn_method(text)
        else:
            return self.ensemble_method(text)
    
    def assess_complexity(self, text):
        """è¯„ä¼°æ–‡æœ¬å¤æ‚åº¦"""
        length = len(text)
        math_symbols = len(re.findall(r'[+\-*/=<>(){}[\]]', text))
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        
        if length < 50 and math_symbols < 3:
            return 'simple'
        elif length < 200 and chinese_chars > length * 0.7:
            return 'standard'
        elif length > 200 or math_symbols > 10:
            return 'complex'
        else:
            return 'uncertain'
    
    def keyword_method(self, text):
        """å…³é”®è¯åŒ¹é…æ–¹æ³•"""
        scores = {}
        for subject, keywords in self.keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            scores[subject] = score
        
        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'æœªçŸ¥'
    
    def rule_method(self, text):
        """è§„åˆ™å¼•æ“æ–¹æ³•"""
        return self.rule_engine.classify(text)
    
    def textcnn_method(self, text):
        """TextCNNæ·±åº¦å­¦ä¹ æ–¹æ³•"""
        processed_text = self.preprocess_text(text)
        prediction = self.textcnn_model.predict(processed_text)
        return self.decode_prediction(prediction)
    
    def ensemble_method(self, text):
        """é›†æˆæ–¹æ³•"""
        results = {
            'keyword': self.keyword_method(text),
            'rule': self.rule_method(text),
            'textcnn': self.textcnn_method(text)
        }
        
        # åŠ æƒæŠ•ç¥¨
        votes = {}
        for method, subject in results.items():
            weight = self.ensemble_weights[method]
            votes[subject] = votes.get(subject, 0) + weight
        
        return max(votes, key=votes.get)
```

#### 2. çŸ¥è¯†ç‚¹åŒ¹é…ç®—æ³•
```python
class KnowledgeMatcher:
    def __init__(self):
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        self.knowledge_vectors = self.load_knowledge_vectors()
        self.semantic_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.semantic_vectors = self.load_semantic_vectors()
    
    def match_knowledge_points(self, question_text):
        """çŸ¥è¯†ç‚¹åŒ¹é…ä¸»æ–¹æ³•"""
        # 1. TF-IDFç›¸ä¼¼åº¦è®¡ç®—
        tfidf_matches = self.tfidf_similarity(question_text)
        
        # 2. è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
        semantic_matches = self.semantic_similarity(question_text)
        
        # 3. å…³é”®è¯åŒ¹é…
        keyword_matches = self.keyword_matching(question_text)
        
        # 4. ç»¼åˆè¯„åˆ†
        final_matches = self.combine_results(
            tfidf_matches, semantic_matches, keyword_matches
        )
        
        return final_matches[:5]  # è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„çŸ¥è¯†ç‚¹
    
    def tfidf_similarity(self, text):
        """TF-IDFç›¸ä¼¼åº¦è®¡ç®—"""
        question_vector = self.tfidf_vectorizer.transform([text])
        similarities = cosine_similarity(question_vector, self.knowledge_vectors)
        
        # è·å–ç›¸ä¼¼åº¦æœ€é«˜çš„çŸ¥è¯†ç‚¹
        top_indices = np.argsort(similarities[0])[-10:][::-1]
        return [(idx, similarities[0][idx]) for idx in top_indices]
    
    def semantic_similarity(self, text):
        """è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—"""
        question_embedding = self.semantic_model.encode([text])
        similarities = cosine_similarity(question_embedding, self.semantic_vectors)
        
        top_indices = np.argsort(similarities[0])[-10:][::-1]
        return [(idx, similarities[0][idx]) for idx in top_indices]
    
    def keyword_matching(self, text):
        """å…³é”®è¯åŒ¹é…"""
        # æå–å…³é”®è¯
        keywords = self.extract_keywords(text)
        
        # ä¸çŸ¥è¯†ç‚¹å…³é”®è¯åº“åŒ¹é…
        matches = []
        for kp_id, kp_keywords in self.knowledge_keywords.items():
            score = len(set(keywords) & set(kp_keywords)) / len(set(keywords) | set(kp_keywords))
            if score > 0.1:  # é˜ˆå€¼è¿‡æ»¤
                matches.append((kp_id, score))
        
        return sorted(matches, key=lambda x: x[1], reverse=True)
    
    def combine_results(self, tfidf_matches, semantic_matches, keyword_matches):
        """ç»¼åˆè¯„åˆ†"""
        combined_scores = {}
        
        # TF-IDFæƒé‡0.4
        for kp_id, score in tfidf_matches:
            combined_scores[kp_id] = combined_scores.get(kp_id, 0) + score * 0.4
        
        # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡0.4
        for kp_id, score in semantic_matches:
            combined_scores[kp_id] = combined_scores.get(kp_id, 0) + score * 0.4
        
        # å…³é”®è¯åŒ¹é…æƒé‡0.2
        for kp_id, score in keyword_matches:
            combined_scores[kp_id] = combined_scores.get(kp_id, 0) + score * 0.2
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        return sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)
```


## ğŸ” é‡åˆ°çš„é—®é¢˜

### 1ï¼šçŸ¥è¯†ç‚¹å±‚çº§åˆ’åˆ†å¤æ‚
**é—®é¢˜**: ä¸åŒå­¦ç§‘çš„çŸ¥è¯†ç‚¹å±‚çº§æ·±åº¦ä¸ä¸€è‡´
- æ•°å­¦ï¼šé€šå¸¸æœ‰3-4å±‚ï¼ˆç« èŠ‚â†’å°èŠ‚â†’çŸ¥è¯†ç‚¹â†’å­çŸ¥è¯†ç‚¹ï¼‰
- è¯­æ–‡ï¼šå±‚çº§è¾ƒæµ…ï¼Œå¤šä¸º2-3å±‚ï¼ˆå•å…ƒâ†’è¯¾æ–‡â†’çŸ¥è¯†ç‚¹ï¼‰
- è‹±è¯­ï¼šè¯­æ³•å’Œè¯æ±‡åˆ†ç±»å¤æ‚ï¼Œå±‚çº§ä¸ç»Ÿä¸€
- ç†ç§‘ï¼šå®éªŒã€ç†è®ºã€åº”ç”¨ä¸‰ä¸ªç»´åº¦äº¤å‰

****

### 2ï¼šé¢˜ç›®ç±»å‹å¤šæ ·åŒ–
**é—®é¢˜**: é€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€åº”ç”¨é¢˜ç­‰ç±»å‹å·®å¼‚å¾ˆå¤§
- é€‰æ‹©é¢˜ï¼šéœ€è¦å­˜å‚¨é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆã€å¹²æ‰°é¡¹åˆ†æ
- å¡«ç©ºé¢˜ï¼šéœ€è¦å¤„ç†å¤šä¸ªç©ºä½ã€ç­”æ¡ˆå˜ä½“ã€åŒä¹‰è¯
- åº”ç”¨é¢˜ï¼šéœ€è¦å­˜å‚¨è§£é¢˜æ­¥éª¤ã€è¯„åˆ†æ ‡å‡†ã€å…³é”®ç‚¹
- ä½œæ–‡é¢˜ï¼šéœ€è¦å­˜å‚¨è¯„åˆ†ç»´åº¦ã€èŒƒæ–‡ã€å†™ä½œè¦æ±‚

    

### 3ï¼šæ•°æ®è´¨é‡æ§åˆ¶
**é—®é¢˜**: æ”¶é›†çš„åŸå§‹æ•°æ®æ ¼å¼ä¸ç»Ÿä¸€ï¼Œè´¨é‡å‚å·®ä¸é½
- ä¸åŒæ¥æºçš„æ•™ææ•°æ®æ ¼å¼å·®å¼‚å·¨å¤§
- çŸ¥è¯†ç‚¹å‘½åä¸ç»Ÿä¸€ï¼ˆå¦‚"ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹"vs"äºŒæ¬¡å‡½æ•°"ï¼‰
- é¢˜ç›®ç¼–å·è§„åˆ™ä¸ä¸€è‡´
- éƒ¨åˆ†æ•°æ®å­˜åœ¨é”™è¯¯æˆ–ç¼ºå¤±



## ğŸ“Š æ•°æ®è´¨é‡åˆ†æ

### æ•°æ®æ”¶é›†ç»Ÿè®¡
| å­¦ç§‘ | çŸ¥è¯†ç‚¹æ•°é‡ | é¢˜ç›®æ•°é‡ | æ•°æ®è´¨é‡è¯„åˆ† |
|------|------------|----------|--------------|
| æ•°å­¦ | 85 | 320 | 95% |
| è¯­æ–‡ | 72 | 280 | 92% |
| è‹±è¯­ | 68 | 250 | 90% |
| ç‰©ç† | 45 | 180 | 88% |
| åŒ–å­¦ | 42 | 160 | 87% |
| ç”Ÿç‰© | 38 | 140 | 85% |
| å†å² | 35 | 120 | 83% |
| åœ°ç† | 32 | 110 | 82% |
| æ”¿æ²» | 28 | 100 | 80% |
| **æ€»è®¡** | **445** | **1660** | **88%** |


