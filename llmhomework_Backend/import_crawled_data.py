#!/usr/bin/env python3
"""
å¯¼å…¥çˆ¬å–çš„æ•°æ®åˆ°æ•°æ®åº“
ç›´æ¥ä½¿ç”¨SQLAlchemyæ¨¡å‹è¿›è¡Œå¯¼å…¥
"""

import os
import sys
import pandas as pd
import logging
from datetime import datetime
import time

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(__file__))

# å¯¼å…¥æ•°æ®åº“æ¨¡å‹å’Œæ•°æ®åº“è¿æ¥
from app.models.knowledge_base import (
    Base, Grade, Subject, Chapter, KnowledgePoint, Question,
    QuestionOption, QuestionType
)
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def import_crawled_data():
    """å¯¼å…¥çˆ¬å–çš„æ•°æ®"""
    logger.info("ğŸ”„ å¼€å§‹å¯¼å…¥çˆ¬å–çš„æ•°æ®...")

    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    db_path = os.path.join(os.path.dirname(__file__), "database", "knowledge_base.db")
    engine = create_engine(f"sqlite:///{db_path}", echo=False)
    Session = sessionmaker(bind=engine)
    session = Session()

    try:
        # è¯»å–ç»Ÿä¸€åçš„æ•°æ®
        knowledge_file = os.path.join(os.path.dirname(__file__), "data_collection", "processed", "knowledge_points_unified.csv")
        questions_file = os.path.join(os.path.dirname(__file__), "data_collection", "processed", "questions_unified.csv")

        imported_kp_count = 0
        imported_q_count = 0

        # å¯¼å…¥çŸ¥è¯†ç‚¹
        if os.path.exists(knowledge_file):
            logger.info(f"ğŸ“š å¯¼å…¥çŸ¥è¯†ç‚¹æ•°æ®: {knowledge_file}")
            df_kp = pd.read_csv(knowledge_file)

            for _, row in df_kp.iterrows():
                try:
                    # æŸ¥æ‰¾æˆ–åˆ›å»ºå¹´çº§
                    grade = session.query(Grade).filter_by(code=row.get('grade', 'Grade 7')).first()
                    if not grade:
                        grade = Grade(
                            name=row.get('grade', 'Grade 7'),
                            code=row.get('grade', 'Grade 7'),
                            description=f"å¹´çº§ {row.get('grade', 'Grade 7')}"
                        )
                        session.add(grade)
                        session.flush()

                    # æŸ¥æ‰¾æˆ–åˆ›å»ºå­¦ç§‘
                    subject = session.query(Subject).filter_by(
                        grade_id=grade.id,
                        code=row.get('subject', 'math').lower()
                    ).first()
                    if not subject:
                        subject = Subject(
                            grade_id=grade.id,
                            name=row.get('subject', 'æ•°å­¦'),
                            code=row.get('subject', 'math').lower(),
                            difficulty_level=int(row.get('difficulty_level', 3))
                        )
                        session.add(subject)
                        session.flush()

                    # æŸ¥æ‰¾æˆ–åˆ›å»ºç« èŠ‚
                    chapter = session.query(Chapter).filter_by(
                        subject_id=subject.id,
                        name=row.get('chapter', 'æœªåˆ†ç±»')
                    ).first()
                    if not chapter:
                        chapter = Chapter(
                            subject_id=subject.id,
                            name=row.get('chapter', 'æœªåˆ†ç±»'),
                            code=f"ch_{subject.code}_{len(session.query(Chapter).filter_by(subject_id=subject.id).all()) + 1}",
                            difficulty_level=int(row.get('difficulty_level', 3))
                        )
                        session.add(chapter)
                        session.flush()

                    # åˆ›å»ºçŸ¥è¯†ç‚¹
                    keywords = []
                    if pd.notna(row.get('keywords')):
                        keywords = str(row.get('keywords')).split('|')[:5]

                    knowledge_point = KnowledgePoint(
                        chapter_id=chapter.id,
                        name=str(row.get('name', '')),
                        code=f"kp_{chapter.code}_{len(session.query(KnowledgePoint).filter_by(chapter_id=chapter.id).all()) + 1}",
                        description=str(row.get('description', '')),
                        difficulty_level=int(row.get('difficulty_level', 3)),
                        importance_level=int(row.get('importance_level', 3)),
                        exam_frequency=float(row.get('exam_frequency', 0.5))
                    )
                    session.add(knowledge_point)
                    session.flush()

                    # æ·»åŠ å…³é”®è¯
                    for keyword in keywords:
                        if keyword.strip():
                            from app.models.knowledge_base import KnowledgePointKeyword
                            kp_keyword = KnowledgePointKeyword(
                                knowledge_point_id=knowledge_point.id,
                                keyword=keyword.strip(),
                                weight=1.0
                            )
                            session.add(kp_keyword)

                    imported_kp_count += 1

                except Exception as e:
                    logger.warning(f"è·³è¿‡çŸ¥è¯†ç‚¹ {row.get('name', 'æœªçŸ¥')}: {e}")

            session.commit()
            logger.info(f"âœ… çŸ¥è¯†ç‚¹å¯¼å…¥å®Œæˆ: {imported_kp_count} æ¡")

        # å¯¼å…¥é¢˜ç›®
        if os.path.exists(questions_file):
            logger.info(f"ğŸ“ å¯¼å…¥é¢˜ç›®æ•°æ®: {questions_file}")
            df_q = pd.read_csv(questions_file)

            for _, row in df_q.iterrows():
                try:
                    # æŸ¥æ‰¾å­¦ç§‘
                    subject = session.query(Subject).filter_by(
                        code=str(row.get('subject', 'math')).lower()
                    ).first()
                    if not subject:
                        logger.warning(f"æ‰¾ä¸åˆ°å­¦ç§‘ {row.get('subject')}")
                        continue

                    # åˆ›å»ºé¢˜ç›®
                    question = Question(
                        question_id=str(row.get('question_id', f'q_{int(time.time())}_{imported_q_count}')),
                        subject_id=subject.id,
                        number=str(row.get('number', imported_q_count + 1)),
                        stem=str(row.get('stem', '')),
                        answer=str(row.get('answer', '')),
                        type=QuestionType(str(row.get('question_type', 'choice'))),
                        timestamp=int(time.time()),
                        correct_answer=str(row.get('correct_answer', '')),
                        explanation=str(row.get('explanation', '')),
                        difficulty_level=int(row.get('difficulty_level', 3)),
                        source=str(row.get('source', 'å¯¼å…¥æ•°æ®'))
                    )
                    session.add(question)
                    session.flush()

                    # å¤„ç†é€‰é¡¹
                    options_data = row.get('options', '')
                    if pd.notna(options_data) and options_data:
                        try:
                            import json
                            options_list = json.loads(options_data)
                            if isinstance(options_list, list):
                                for i, option in enumerate(options_list):
                                    if option:
                                        q_option = QuestionOption(
                                            question_id=question.question_id,
                                            option_key=chr(65 + i),  # A, B, C, D...
                                            option_value=str(option),
                                            is_correct=(str(row.get('correct_answer', '')) == chr(65 + i))
                                        )
                                        db_session.add(q_option)
                        except:
                            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
                            pass

                    imported_q_count += 1

                except Exception as e:
                    logger.warning(f"è·³è¿‡é¢˜ç›® {row.get('question_id', 'æœªçŸ¥')}: {e}")

            session.commit()
            logger.info(f"âœ… é¢˜ç›®å¯¼å…¥å®Œæˆ: {imported_q_count} æ¡")

        # ç»Ÿè®¡ä¿¡æ¯
        logger.info("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
        logger.info(f"  - çŸ¥è¯†ç‚¹å·²å¯¼å…¥: {imported_kp_count} æ¡")
        logger.info(f"  - é¢˜ç›®å·²å¯¼å…¥: {imported_q_count} æ¡")

        # æ˜¾ç¤ºå®é™…æ•°æ®åº“ä¸­çš„æ•°æ®
        kp_count = session.query(KnowledgePoint).count()
        q_count = session.query(Question).count()
        logger.info(f"ğŸ“Š æ•°æ®åº“å®é™…æ•°æ®:")
        logger.info(f"  - çŸ¥è¯†ç‚¹æ€»æ•°: {kp_count} æ¡")
        logger.info(f"  - é¢˜ç›®æ€»æ•°: {q_count} æ¡")

        logger.info("ğŸ‰ æ•°æ®å¯¼å…¥å®Œæˆï¼")
        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        session.rollback()
        return False
    finally:
        session.close()

if __name__ == "__main__":
    print("ğŸ”„ å¼€å§‹å¯¼å…¥çˆ¬å–çš„æ•°æ®åˆ°æ•°æ®åº“...")
    success = import_crawled_data()
    
    if success:
        print("âœ… æ•°æ®å¯¼å…¥æˆåŠŸï¼")
        print("\nğŸ“‹ åç»­æ“ä½œå»ºè®®:")
        print("1. è¿è¡Œ python test_day7_complete.py æµ‹è¯•ç³»ç»Ÿ")
        print("2. å¯åŠ¨åç«¯æœåŠ¡ python run.py")
        print("3. æµ‹è¯•çŸ¥è¯†åŒ¹é…åŠŸèƒ½")
    else:
        print("âŒ æ•°æ®å¯¼å…¥å¤±è´¥")
