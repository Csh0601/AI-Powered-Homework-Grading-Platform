#!/usr/bin/env python3
"""
åŸºç¡€æ•°æ®å­˜å‚¨æœåŠ¡
Day 7 ä»»åŠ¡ - æ­å»ºåŸºç¡€çš„æ•°æ®å­˜å‚¨æœåŠ¡

ä¸»è¦åŠŸèƒ½ï¼š
1. çŸ¥è¯†ç‚¹æ•°æ®ç®¡ç†
2. é¢˜ç›®æ•°æ®ç®¡ç†
3. æ‰¹æ”¹è®°å½•ç®¡ç†
4. æ•°æ®å¯¼å…¥å¯¼å‡º
5. æ•°æ®éªŒè¯å’Œæ¸…ç†

æŠ€æœ¯è¦ç‚¹ï¼š
- æ•°æ®ä¸€è‡´æ€§ä¿è¯
- äº‹åŠ¡ç®¡ç†
- æ‰¹é‡æ“ä½œä¼˜åŒ–
- æ•°æ®å¤‡ä»½æ¢å¤
- æ€§èƒ½ç›‘æ§
"""

import os
import json
import sqlite3
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union, Tuple
import hashlib
import uuid
from pathlib import Path
import shutil
import threading
from contextlib import contextmanager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataStorageService:
    """åŸºç¡€æ•°æ®å­˜å‚¨æœåŠ¡"""
    
    def __init__(self, db_path: str = None, backup_dir: str = None):
        """
        åˆå§‹åŒ–æ•°æ®å­˜å‚¨æœåŠ¡
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            backup_dir: å¤‡ä»½ç›®å½•è·¯å¾„
        """
        # æ•°æ®åº“é…ç½®
        self.db_path = db_path or os.path.join(
            os.path.dirname(__file__), '..', '..', 'database', 'knowledge_base.db'
        )
        
        # å¤‡ä»½é…ç½®
        self.backup_dir = backup_dir or os.path.join(
            os.path.dirname(__file__), '..', '..', 'backups'
        )
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        os.makedirs(self.backup_dir, exist_ok=True)
        
        # çº¿ç¨‹é”
        self._lock = threading.Lock()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_operations': 0,
            'successful_operations': 0,
            'failed_operations': 0,
            'last_backup': None,
            'db_size_bytes': 0
        }
        
        logger.info(f"âœ… æ•°æ®å­˜å‚¨æœåŠ¡åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # çŸ¥è¯†ç‚¹è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS knowledge_points (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        knowledge_point_id TEXT UNIQUE NOT NULL,
                        name TEXT NOT NULL,
                        category TEXT,
                        subject TEXT,
                        difficulty_level INTEGER DEFAULT 1,
                        grade_level INTEGER DEFAULT 7,
                        keywords TEXT, -- JSONæ ¼å¼
                        patterns TEXT, -- JSONæ ¼å¼
                        description TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # é¢˜ç›®è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS questions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        question_id TEXT UNIQUE NOT NULL,
                        number TEXT,
                        stem TEXT NOT NULL,
                        answer TEXT,
                        correct_answer TEXT,
                        type TEXT,
                        subject TEXT,
                        difficulty_level INTEGER DEFAULT 1,
                        timestamp INTEGER,
                        source TEXT,
                        options TEXT, -- JSONæ ¼å¼
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # é¢˜ç›®çŸ¥è¯†ç‚¹å…³è”è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS question_knowledge_points (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        question_id TEXT NOT NULL,
                        knowledge_point_id TEXT NOT NULL,
                        relevance_score REAL DEFAULT 1.0,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (question_id) REFERENCES questions(question_id),
                        FOREIGN KEY (knowledge_point_id) REFERENCES knowledge_points(knowledge_point_id),
                        UNIQUE(question_id, knowledge_point_id)
                    )
                ''')
                
                # æ‰¹æ”¹è®°å½•è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS grading_records (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        record_id TEXT UNIQUE NOT NULL,
                        task_id TEXT NOT NULL,
                        question_id TEXT NOT NULL,
                        user_id TEXT,
                        is_correct BOOLEAN,
                        score REAL,
                        explanation TEXT,
                        grading_method TEXT,
                        confidence REAL DEFAULT 1.0,
                        processing_time_ms REAL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (question_id) REFERENCES questions(question_id)
                    )
                ''')
                
                # ç”¨æˆ·å­¦ä¹ è®°å½•è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS learning_records (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        user_id TEXT NOT NULL,
                        question_id TEXT NOT NULL,
                        knowledge_point_id TEXT,
                        answer_time INTEGER, -- ç­”é¢˜ç”¨æ—¶ï¼ˆç§’ï¼‰
                        is_correct BOOLEAN,
                        attempt_count INTEGER DEFAULT 1,
                        confidence_level INTEGER, -- å­¦ç”Ÿä¿¡å¿ƒç­‰çº§(1-5)
                        answered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (question_id) REFERENCES questions(question_id),
                        FOREIGN KEY (knowledge_point_id) REFERENCES knowledge_points(knowledge_point_id)
                    )
                ''')
                
                # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿è¡¨åˆ›å»ºå®Œæˆ
                conn.commit()
                
                # åˆ›å»ºç´¢å¼•
                indexes = [
                    "CREATE INDEX IF NOT EXISTS idx_kp_subject ON knowledge_points(subject)",
                    "CREATE INDEX IF NOT EXISTS idx_kp_difficulty ON knowledge_points(difficulty_level)",
                    "CREATE INDEX IF NOT EXISTS idx_q_subject ON questions(subject)",
                    "CREATE INDEX IF NOT EXISTS idx_q_type ON questions(type)",
                    "CREATE INDEX IF NOT EXISTS idx_q_difficulty ON questions(difficulty_level)",
                    "CREATE INDEX IF NOT EXISTS idx_qkp_question ON question_knowledge_points(question_id)",
                    "CREATE INDEX IF NOT EXISTS idx_qkp_knowledge ON question_knowledge_points(knowledge_point_id)",
                    "CREATE INDEX IF NOT EXISTS idx_gr_task ON grading_records(task_id)",
                    "CREATE INDEX IF NOT EXISTS idx_gr_user ON grading_records(user_id)",
                    "CREATE INDEX IF NOT EXISTS idx_lr_user ON learning_records(user_id)",
                    "CREATE INDEX IF NOT EXISTS idx_lr_question ON learning_records(question_id)"
                ]
                
                for index_sql in indexes:
                    cursor.execute(index_sql)
                
                conn.commit()
                logger.info("âœ… æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥ï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
        conn = None
        try:
            conn = sqlite3.connect(self.db_path, timeout=30.0)
            conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼
            yield conn
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            raise
        finally:
            if conn:
                conn.close()
    
    def _update_stats(self, success: bool = True):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            self.stats['total_operations'] += 1
            if success:
                self.stats['successful_operations'] += 1
            else:
                self.stats['failed_operations'] += 1
            
            # æ›´æ–°æ•°æ®åº“å¤§å°
            try:
                self.stats['db_size_bytes'] = os.path.getsize(self.db_path)
            except:
                pass
    
    # ========================================
    # çŸ¥è¯†ç‚¹æ•°æ®ç®¡ç†
    # ========================================
    
    def save_knowledge_point(self, knowledge_point: Dict[str, Any]) -> bool:
        """ä¿å­˜çŸ¥è¯†ç‚¹æ•°æ®"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # å‡†å¤‡æ•°æ®
                data = {
                    'knowledge_point_id': knowledge_point.get('id', str(uuid.uuid4())),
                    'name': knowledge_point.get('name', ''),
                    'category': knowledge_point.get('category', ''),
                    'subject': knowledge_point.get('subject', ''),
                    'difficulty_level': knowledge_point.get('difficulty_level', 1),
                    'grade_level': knowledge_point.get('grade_level', 7),
                    'keywords': json.dumps(knowledge_point.get('keywords', []), ensure_ascii=False),
                    'patterns': json.dumps(knowledge_point.get('patterns', []), ensure_ascii=False),
                    'description': knowledge_point.get('description', ''),
                    'updated_at': datetime.utcnow().isoformat()
                }
                
                # æ’å…¥æˆ–æ›´æ–°
                cursor.execute('''
                    INSERT OR REPLACE INTO knowledge_points (
                        knowledge_point_id, name, category, subject, difficulty_level, 
                        grade_level, keywords, patterns, description, updated_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    data['knowledge_point_id'], data['name'], data['category'],
                    data['subject'], data['difficulty_level'], data['grade_level'],
                    data['keywords'], data['patterns'], data['description'],
                    data['updated_at']
                ))
                
                conn.commit()
                self._update_stats(True)
                return True
                
        except Exception as e:
            logger.error(f"ä¿å­˜çŸ¥è¯†ç‚¹å¤±è´¥: {e}")
            self._update_stats(False)
            return False
    
    def get_knowledge_points(self, subject: str = None, difficulty: int = None, 
                           limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """è·å–çŸ¥è¯†ç‚¹åˆ—è¡¨"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ„å»ºæŸ¥è¯¢
                sql = "SELECT * FROM knowledge_points WHERE 1=1"
                params = []
                
                if subject:
                    sql += " AND subject = ?"
                    params.append(subject)
                
                if difficulty:
                    sql += " AND difficulty_level = ?"
                    params.append(difficulty)
                
                sql += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
                params.extend([limit, offset])
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                results = []
                for row in rows:
                    kp = dict(row)
                    # è§£æJSONå­—æ®µ
                    try:
                        kp['keywords'] = json.loads(kp['keywords']) if kp['keywords'] else []
                        kp['patterns'] = json.loads(kp['patterns']) if kp['patterns'] else []
                    except:
                        kp['keywords'] = []
                        kp['patterns'] = []
                    results.append(kp)
                
                self._update_stats(True)
                return results
                
        except Exception as e:
            logger.error(f"è·å–çŸ¥è¯†ç‚¹å¤±è´¥: {e}")
            self._update_stats(False)
            return []
    
    def search_knowledge_points(self, query: str, subject: str = None) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†ç‚¹"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ„å»ºæœç´¢æŸ¥è¯¢
                sql = '''
                    SELECT * FROM knowledge_points 
                    WHERE (name LIKE ? OR description LIKE ? OR keywords LIKE ?)
                '''
                params = [f'%{query}%', f'%{query}%', f'%{query}%']
                
                if subject:
                    sql += " AND subject = ?"
                    params.append(subject)
                
                sql += " ORDER BY name"
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                results = []
                for row in rows:
                    kp = dict(row)
                    try:
                        kp['keywords'] = json.loads(kp['keywords']) if kp['keywords'] else []
                        kp['patterns'] = json.loads(kp['patterns']) if kp['patterns'] else []
                    except:
                        kp['keywords'] = []
                        kp['patterns'] = []
                    results.append(kp)
                
                self._update_stats(True)
                return results
                
        except Exception as e:
            logger.error(f"æœç´¢çŸ¥è¯†ç‚¹å¤±è´¥: {e}")
            self._update_stats(False)
            return []
    
    # ========================================
    # é¢˜ç›®æ•°æ®ç®¡ç†
    # ========================================
    
    def save_question(self, question: Dict[str, Any]) -> bool:
        """ä¿å­˜é¢˜ç›®æ•°æ®"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # å‡†å¤‡æ•°æ®
                data = {
                    'question_id': question.get('question_id', str(uuid.uuid4())),
                    'number': question.get('number', ''),
                    'stem': question.get('stem', ''),
                    'answer': question.get('answer', ''),
                    'correct_answer': question.get('correct_answer', ''),
                    'type': question.get('type', ''),
                    'subject': question.get('subject', ''),
                    'difficulty_level': question.get('difficulty_level', 1),
                    'timestamp': question.get('timestamp', int(time.time())),
                    'source': question.get('source', ''),
                    'options': json.dumps(question.get('options', {}), ensure_ascii=False),
                    'updated_at': datetime.utcnow().isoformat()
                }
                
                # æ’å…¥æˆ–æ›´æ–°
                cursor.execute('''
                    INSERT OR REPLACE INTO questions (
                        question_id, number, stem, answer, correct_answer, type,
                        subject, difficulty_level, timestamp, source, options, updated_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    data['question_id'], data['number'], data['stem'], data['answer'],
                    data['correct_answer'], data['type'], data['subject'],
                    data['difficulty_level'], data['timestamp'], data['source'],
                    data['options'], data['updated_at']
                ))
                
                conn.commit()
                self._update_stats(True)
                return True
                
        except Exception as e:
            logger.error(f"ä¿å­˜é¢˜ç›®å¤±è´¥: {e}")
            self._update_stats(False)
            return False
    
    def get_questions(self, subject: str = None, question_type: str = None,
                     difficulty: int = None, limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """è·å–é¢˜ç›®åˆ—è¡¨"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ„å»ºæŸ¥è¯¢
                sql = "SELECT * FROM questions WHERE 1=1"
                params = []
                
                if subject:
                    sql += " AND subject = ?"
                    params.append(subject)
                
                if question_type:
                    sql += " AND type = ?"
                    params.append(question_type)
                
                if difficulty:
                    sql += " AND difficulty_level = ?"
                    params.append(difficulty)
                
                sql += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
                params.extend([limit, offset])
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                results = []
                for row in rows:
                    question = dict(row)
                    # è§£æJSONå­—æ®µ
                    try:
                        question['options'] = json.loads(question['options']) if question['options'] else {}
                    except:
                        question['options'] = {}
                    results.append(question)
                
                self._update_stats(True)
                return results
                
        except Exception as e:
            logger.error(f"è·å–é¢˜ç›®å¤±è´¥: {e}")
            self._update_stats(False)
            return []
    
    def associate_question_knowledge_points(self, question_id: str, 
                                          knowledge_point_ids: List[str],
                                          relevance_scores: List[float] = None) -> bool:
        """å…³è”é¢˜ç›®å’ŒçŸ¥è¯†ç‚¹"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # åˆ é™¤ç°æœ‰å…³è”
                cursor.execute(
                    "DELETE FROM question_knowledge_points WHERE question_id = ?",
                    (question_id,)
                )
                
                # æ’å…¥æ–°å…³è”
                for i, kp_id in enumerate(knowledge_point_ids):
                    relevance = relevance_scores[i] if relevance_scores and i < len(relevance_scores) else 1.0
                    cursor.execute('''
                        INSERT INTO question_knowledge_points 
                        (question_id, knowledge_point_id, relevance_score)
                        VALUES (?, ?, ?)
                    ''', (question_id, kp_id, relevance))
                
                conn.commit()
                self._update_stats(True)
                return True
                
        except Exception as e:
            logger.error(f"å…³è”é¢˜ç›®çŸ¥è¯†ç‚¹å¤±è´¥: {e}")
            self._update_stats(False)
            return False
    
    # ========================================
    # æ‰¹æ”¹è®°å½•ç®¡ç†
    # ========================================
    
    def save_grading_record(self, record: Dict[str, Any]) -> bool:
        """ä¿å­˜æ‰¹æ”¹è®°å½•"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                data = {
                    'record_id': record.get('record_id', str(uuid.uuid4())),
                    'task_id': record.get('task_id', ''),
                    'question_id': record.get('question_id', ''),
                    'user_id': record.get('user_id', ''),
                    'is_correct': record.get('is_correct', False),
                    'score': record.get('score', 0.0),
                    'explanation': record.get('explanation', ''),
                    'grading_method': record.get('grading_method', ''),
                    'confidence': record.get('confidence', 1.0),
                    'processing_time_ms': record.get('processing_time_ms', 0.0)
                }
                
                cursor.execute('''
                    INSERT OR REPLACE INTO grading_records (
                        record_id, task_id, question_id, user_id, is_correct,
                        score, explanation, grading_method, confidence, processing_time_ms
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    data['record_id'], data['task_id'], data['question_id'],
                    data['user_id'], data['is_correct'], data['score'],
                    data['explanation'], data['grading_method'], 
                    data['confidence'], data['processing_time_ms']
                ))
                
                conn.commit()
                self._update_stats(True)
                return True
                
        except Exception as e:
            logger.error(f"ä¿å­˜æ‰¹æ”¹è®°å½•å¤±è´¥: {e}")
            self._update_stats(False)
            return False
    
    def get_grading_records(self, task_id: str = None, user_id: str = None,
                           limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """è·å–æ‰¹æ”¹è®°å½•"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                sql = "SELECT * FROM grading_records WHERE 1=1"
                params = []
                
                if task_id:
                    sql += " AND task_id = ?"
                    params.append(task_id)
                
                if user_id:
                    sql += " AND user_id = ?"
                    params.append(user_id)
                
                sql += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
                params.extend([limit, offset])
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                results = [dict(row) for row in rows]
                self._update_stats(True)
                return results
                
        except Exception as e:
            logger.error(f"è·å–æ‰¹æ”¹è®°å½•å¤±è´¥: {e}")
            self._update_stats(False)
            return []
    
    # ========================================
    # æ•°æ®å¯¼å…¥å¯¼å‡º
    # ========================================
    
    def import_data_from_json(self, file_path: str, data_type: str = 'auto') -> Dict[str, Any]:
        """ä»JSONæ–‡ä»¶å¯¼å…¥æ•°æ®"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            results = {
                'total_records': 0,
                'successful_imports': 0,
                'failed_imports': 0,
                'errors': []
            }
            
            if data_type == 'auto':
                # è‡ªåŠ¨æ£€æµ‹æ•°æ®ç±»å‹
                if isinstance(data, list) and data:
                    sample = data[0]
                    if 'knowledge_point_id' in sample or 'name' in sample:
                        data_type = 'knowledge_points'
                    elif 'question_id' in sample or 'stem' in sample:
                        data_type = 'questions'
                    else:
                        data_type = 'unknown'
            
            if data_type == 'knowledge_points':
                results['total_records'] = len(data)
                for item in data:
                    if self.save_knowledge_point(item):
                        results['successful_imports'] += 1
                    else:
                        results['failed_imports'] += 1
                        results['errors'].append(f"å¯¼å…¥çŸ¥è¯†ç‚¹å¤±è´¥: {item.get('name', 'Unknown')}")
            
            elif data_type == 'questions':
                results['total_records'] = len(data)
                for item in data:
                    if self.save_question(item):
                        results['successful_imports'] += 1
                    else:
                        results['failed_imports'] += 1
                        results['errors'].append(f"å¯¼å…¥é¢˜ç›®å¤±è´¥: {item.get('question_id', 'Unknown')}")
            
            logger.info(f"æ•°æ®å¯¼å…¥å®Œæˆ: {results['successful_imports']}/{results['total_records']}")
            return results
            
        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            return {
                'total_records': 0,
                'successful_imports': 0,
                'failed_imports': 0,
                'errors': [str(e)]
            }
    
    def export_data_to_json(self, file_path: str, data_type: str, **filters) -> bool:
        """å¯¼å‡ºæ•°æ®åˆ°JSONæ–‡ä»¶"""
        try:
            if data_type == 'knowledge_points':
                data = self.get_knowledge_points(**filters)
            elif data_type == 'questions':
                data = self.get_questions(**filters)
            elif data_type == 'grading_records':
                data = self.get_grading_records(**filters)
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
                return False
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"æ•°æ®å¯¼å‡ºå®Œæˆ: {len(data)} æ¡è®°å½• -> {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    # ========================================
    # æ•°æ®å¤‡ä»½æ¢å¤
    # ========================================
    
    def create_backup(self, backup_name: str = None) -> str:
        """åˆ›å»ºæ•°æ®å¤‡ä»½"""
        try:
            if not backup_name:
                backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            
            backup_path = os.path.join(self.backup_dir, backup_name)
            shutil.copy2(self.db_path, backup_path)
            
            self.stats['last_backup'] = datetime.utcnow().isoformat()
            logger.info(f"æ•°æ®å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_path}")
            return backup_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
            return ""
    
    def restore_backup(self, backup_path: str) -> bool:
        """æ¢å¤æ•°æ®å¤‡ä»½"""
        try:
            if not os.path.exists(backup_path):
                logger.error(f"å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
                return False
            
            # åˆ›å»ºå½“å‰æ•°æ®çš„å¤‡ä»½
            current_backup = self.create_backup("pre_restore_backup.db")
            
            # æ¢å¤å¤‡ä»½
            shutil.copy2(backup_path, self.db_path)
            
            logger.info(f"æ•°æ®æ¢å¤æˆåŠŸ: {backup_path}")
            logger.info(f"åŸæ•°æ®å·²å¤‡ä»½åˆ°: {current_backup}")
            return True
            
        except Exception as e:
            logger.error(f"æ¢å¤å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    # ========================================
    # ç»Ÿè®¡å’Œç›‘æ§
    # ========================================
    
    def get_database_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                stats = {
                    'database_info': {
                        'db_path': self.db_path,
                        'db_size_mb': round(os.path.getsize(self.db_path) / (1024 * 1024), 2),
                        'last_modified': datetime.fromtimestamp(
                            os.path.getmtime(self.db_path)
                        ).isoformat()
                    },
                    'table_counts': {},
                    'operation_stats': self.stats.copy()
                }
                
                # è·å–å„è¡¨è®°å½•æ•°
                tables = ['knowledge_points', 'questions', 'question_knowledge_points', 
                         'grading_records', 'learning_records']
                
                for table in tables:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    stats['table_counts'][table] = count
                
                # è·å–ä¸€äº›ç»Ÿè®¡ä¿¡æ¯
                cursor.execute('''
                    SELECT subject, COUNT(*) 
                    FROM knowledge_points 
                    GROUP BY subject
                ''')
                stats['knowledge_points_by_subject'] = dict(cursor.fetchall())
                
                cursor.execute('''
                    SELECT type, COUNT(*) 
                    FROM questions 
                    GROUP BY type
                ''')
                stats['questions_by_type'] = dict(cursor.fetchall())
                
                self._update_stats(True)
                return stats
                
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            self._update_stats(False)
            return {}
    
    def cleanup_old_records(self, days: int = 30) -> int:
        """æ¸…ç†æ—§è®°å½•"""
        try:
            cutoff_date = datetime.utcnow() - timedelta(days=days)
            
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ¸…ç†æ—§çš„æ‰¹æ”¹è®°å½•
                cursor.execute('''
                    DELETE FROM grading_records 
                    WHERE created_at < ?
                ''', (cutoff_date.isoformat(),))
                
                deleted_count = cursor.rowcount
                conn.commit()
                
                logger.info(f"æ¸…ç†å®Œæˆ: åˆ é™¤äº† {deleted_count} æ¡æ—§è®°å½•")
                self._update_stats(True)
                return deleted_count
                
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§è®°å½•å¤±è´¥: {e}")
            self._update_stats(False)
            return 0
    
    def validate_data_integrity(self) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                
                validation_results = {
                    'total_checks': 0,
                    'passed_checks': 0,
                    'failed_checks': 0,
                    'issues': []
                }
                
                # æ£€æŸ¥å­¤ç«‹çš„å…³è”è®°å½•
                cursor.execute('''
                    SELECT COUNT(*) FROM question_knowledge_points qkp
                    LEFT JOIN questions q ON qkp.question_id = q.question_id
                    WHERE q.question_id IS NULL
                ''')
                orphaned_associations = cursor.fetchone()[0]
                validation_results['total_checks'] += 1
                if orphaned_associations > 0:
                    validation_results['failed_checks'] += 1
                    validation_results['issues'].append(
                        f"å‘ç° {orphaned_associations} ä¸ªå­¤ç«‹çš„é¢˜ç›®-çŸ¥è¯†ç‚¹å…³è”"
                    )
                else:
                    validation_results['passed_checks'] += 1
                
                # æ£€æŸ¥ç¼ºå°‘å…³è”çš„é¢˜ç›®
                cursor.execute('''
                    SELECT COUNT(*) FROM questions q
                    LEFT JOIN question_knowledge_points qkp ON q.question_id = qkp.question_id
                    WHERE qkp.question_id IS NULL
                ''')
                unlinked_questions = cursor.fetchone()[0]
                validation_results['total_checks'] += 1
                if unlinked_questions > 0:
                    validation_results['issues'].append(
                        f"å‘ç° {unlinked_questions} ä¸ªæœªå…³è”çŸ¥è¯†ç‚¹çš„é¢˜ç›®"
                    )
                    validation_results['failed_checks'] += 1
                else:
                    validation_results['passed_checks'] += 1
                
                # æ£€æŸ¥é‡å¤æ•°æ®
                cursor.execute('''
                    SELECT question_id, COUNT(*) 
                    FROM questions 
                    GROUP BY question_id 
                    HAVING COUNT(*) > 1
                ''')
                duplicate_questions = cursor.fetchall()
                validation_results['total_checks'] += 1
                if duplicate_questions:
                    validation_results['failed_checks'] += 1
                    validation_results['issues'].append(
                        f"å‘ç° {len(duplicate_questions)} ä¸ªé‡å¤çš„é¢˜ç›®ID"
                    )
                else:
                    validation_results['passed_checks'] += 1
                
                logger.info(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å®Œæˆ: {validation_results['passed_checks']}/{validation_results['total_checks']} é€šè¿‡")
                return validation_results
                
        except Exception as e:
            logger.error(f"æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return {
                'total_checks': 0,
                'passed_checks': 0,
                'failed_checks': 1,
                'issues': [str(e)]
            }

def test_data_storage_service():
    """æµ‹è¯•æ•°æ®å­˜å‚¨æœåŠ¡"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®å­˜å‚¨æœåŠ¡...")
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    service = DataStorageService()
    
    # æµ‹è¯•çŸ¥è¯†ç‚¹æ“ä½œ
    test_kp = {
        'id': 'test_kp_001',
        'name': 'æµ‹è¯•çŸ¥è¯†ç‚¹',
        'subject': 'math',
        'difficulty_level': 2,
        'keywords': ['æµ‹è¯•', 'çŸ¥è¯†ç‚¹'],
        'description': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•çŸ¥è¯†ç‚¹'
    }
    
    print("ğŸ“ æµ‹è¯•ä¿å­˜çŸ¥è¯†ç‚¹...")
    if service.save_knowledge_point(test_kp):
        print("âœ… çŸ¥è¯†ç‚¹ä¿å­˜æˆåŠŸ")
    else:
        print("âŒ çŸ¥è¯†ç‚¹ä¿å­˜å¤±è´¥")
    
    print("ğŸ” æµ‹è¯•æŸ¥è¯¢çŸ¥è¯†ç‚¹...")
    kps = service.get_knowledge_points(subject='math', limit=5)
    print(f"âœ… æŸ¥è¯¢åˆ° {len(kps)} ä¸ªæ•°å­¦çŸ¥è¯†ç‚¹")
    
    # æµ‹è¯•é¢˜ç›®æ“ä½œ
    test_question = {
        'question_id': 'test_q_001',
        'stem': 'æµ‹è¯•é¢˜ç›®å†…å®¹',
        'answer': 'æµ‹è¯•ç­”æ¡ˆ',
        'type': 'choice',
        'subject': 'math',
        'difficulty_level': 2
    }
    
    print("ğŸ“ æµ‹è¯•ä¿å­˜é¢˜ç›®...")
    if service.save_question(test_question):
        print("âœ… é¢˜ç›®ä¿å­˜æˆåŠŸ")
    else:
        print("âŒ é¢˜ç›®ä¿å­˜å¤±è´¥")
    
    # æµ‹è¯•å…³è”
    print("ğŸ”— æµ‹è¯•å…³è”é¢˜ç›®å’ŒçŸ¥è¯†ç‚¹...")
    if service.associate_question_knowledge_points('test_q_001', ['test_kp_001']):
        print("âœ… å…³è”åˆ›å»ºæˆåŠŸ")
    else:
        print("âŒ å…³è”åˆ›å»ºå¤±è´¥")
    
    # æµ‹è¯•ç»Ÿè®¡
    print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯...")
    stats = service.get_database_statistics()
    print(f"âœ… æ•°æ®åº“å¤§å°: {stats.get('database_info', {}).get('db_size_mb', 0)} MB")
    print(f"âœ… çŸ¥è¯†ç‚¹æ•°é‡: {stats.get('table_counts', {}).get('knowledge_points', 0)}")
    print(f"âœ… é¢˜ç›®æ•°é‡: {stats.get('table_counts', {}).get('questions', 0)}")
    
    print("ğŸ¯ æ•°æ®å­˜å‚¨æœåŠ¡æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_data_storage_service()
