#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è¿œç¨‹æœåŠ¡å™¨qwen3:30Bæ¨¡å‹è¿æ¥
"""

import sys
import os
import requests
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from app.config import Config

def test_server_connectivity():
    """æµ‹è¯•æœåŠ¡å™¨è¿é€šæ€§"""
    print("=" * 60)
    print("æµ‹è¯•æœåŠ¡å™¨è¿é€šæ€§")
    print("=" * 60)
    
    server_url = f"http://{Config.SERVER_HOST}:{Config.OLLAMA_PORT}"
    
    try:
        # æµ‹è¯•åŸºæœ¬è¿æ¥
        print(f"æµ‹è¯•æœåŠ¡å™¨åœ°å€: {server_url}")
        response = requests.get(f"{server_url}/api/version", timeout=10)
        
        if response.status_code == 200:
            print("âœ… æœåŠ¡å™¨è¿æ¥æˆåŠŸï¼")
            version_info = response.json()
            print(f"Ollamaç‰ˆæœ¬: {version_info.get('version', 'unknown')}")
            return True
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("1. æœåŠ¡å™¨IPåœ°å€æ˜¯å¦æ­£ç¡®")
        print("2. æœåŠ¡å™¨é˜²ç«å¢™æ˜¯å¦å¼€æ”¾11434ç«¯å£")
        print("3. OllamaæœåŠ¡æ˜¯å¦åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ")
        return False
    except requests.exceptions.Timeout:
        print("âŒ è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return False
    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_availability():
    """æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•qwen3:30Bæ¨¡å‹å¯ç”¨æ€§")
    print("=" * 60)
    
    server_url = Config.OLLAMA_BASE_URL
    
    try:
        # è·å–æ¨¡å‹åˆ—è¡¨
        print("è·å–æœåŠ¡å™¨ä¸Šçš„æ¨¡å‹åˆ—è¡¨...")
        response = requests.get(f"{server_url}/api/tags", timeout=15)
        
        if response.status_code == 200:
            models_data = response.json()
            models = [model['name'] for model in models_data.get('models', [])]
            
            print(f"æœåŠ¡å™¨ä¸Šå¯ç”¨çš„æ¨¡å‹: {models}")
            
            # æ£€æŸ¥qwen3:30Bæ˜¯å¦å­˜åœ¨
            target_models = ['qwen3:30B', 'qwen3:30b', 'qwen3:30B']
            available_model = None
            
            for model in target_models:
                if model in models:
                    available_model = model
                    break
            
            if available_model:
                print(f"âœ… æ‰¾åˆ°ç›®æ ‡æ¨¡å‹: {available_model}")
                return available_model
            else:
                print("âŒ æœªæ‰¾åˆ°qwen3:30Bæ¨¡å‹")
                print("è¯·åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ: ollama pull qwen3:30B")
                return None
        else:
            print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        return None

def test_model_generation():
    """æµ‹è¯•æ¨¡å‹ç”ŸæˆåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ¨¡å‹ç”ŸæˆåŠŸèƒ½")
    print("=" * 60)
    
    server_url = Config.OLLAMA_BASE_URL
    model_name = Config.QWEN_MODEL_NAME
    
    try:
        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        print("å‘é€æµ‹è¯•è¯·æ±‚...")
        
        # å‡†å¤‡è¯·æ±‚æ•°æ®
        data = {
            "model": model_name,
            "prompt": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
            "stream": False,
            "options": {
                "num_predict": 100,
                "temperature": 0.1
            }
        }
        
        # å‘é€ç”Ÿæˆè¯·æ±‚
        response = requests.post(
            f"{server_url}/api/generate",
            json=data,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            generated_text = result.get('response', '')
            
            print("âœ… æ¨¡å‹ç”ŸæˆæˆåŠŸï¼")
            print(f"ç”Ÿæˆå†…å®¹: {generated_text}")
            print(f"ç”Ÿæˆæ—¶é—´: {result.get('total_duration', 0) / 1000000:.2f}ms")
            return True
        else:
            print(f"âŒ ç”Ÿæˆè¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ollama_client():
    """ä½¿ç”¨ollamaå®¢æˆ·ç«¯æµ‹è¯•è¿æ¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•ollamaå®¢æˆ·ç«¯è¿æ¥")
    print("=" * 60)
    
    try:
        from app.services.qwen_service import QwenService
        
        print(f"æ­£åœ¨åˆ›å»ºQwenServiceå®ä¾‹...")
        print(f"ç›®æ ‡æœåŠ¡å™¨: {Config.OLLAMA_BASE_URL}")
        print(f"ç›®æ ‡æ¨¡å‹: {Config.QWEN_MODEL_NAME}")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        qwen_service = QwenService(Config.QWEN_MODEL_NAME)
        print("âœ… QwenServiceåˆ›å»ºæˆåŠŸï¼")
        
        # æµ‹è¯•ç®€å•å¯¹è¯
        print("\næµ‹è¯•ç®€å•å¯¹è¯...")
        test_prompt = "è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ"
        response = qwen_service.generate_response(test_prompt, max_tokens=50)
        
        print(f"æµ‹è¯•é—®é¢˜: {test_prompt}")
        print(f"æ¨¡å‹å›ç­”: {response}")
        
        if response and len(response.strip()) > 0:
            print("âœ… å¯¹è¯æµ‹è¯•æˆåŠŸï¼")
            return True
        else:
            print("âŒ æ¨¡å‹æ²¡æœ‰è¿”å›æœ‰æ•ˆå“åº”")
            return False
            
    except Exception as e:
        print(f"âŒ ollamaå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•è¿œç¨‹qwen3:30Bæ¨¡å‹è¿æ¥...")
    print(f"æœåŠ¡å™¨ä¿¡æ¯:")
    print(f"  IPåœ°å€: {Config.SERVER_HOST}")
    print(f"  ç«¯å£: {Config.OLLAMA_PORT}")
    print(f"  å®Œæ•´URL: {Config.OLLAMA_BASE_URL}")
    print(f"  ç›®æ ‡æ¨¡å‹: {Config.LLAMA_MODEL_NAME}")
    
    # æ­¥éª¤1: æµ‹è¯•æœåŠ¡å™¨è¿é€šæ€§
    if not test_server_connectivity():
        print("\nâŒ æœåŠ¡å™¨è¿æ¥å¤±è´¥ï¼Œè¯·å…ˆè§£å†³è¿æ¥é—®é¢˜")
        return
    
    # æ­¥éª¤2: æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§
    available_model = test_model_availability()
    if not available_model:
        print("\nâŒ æ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·å…ˆåœ¨æœåŠ¡å™¨ä¸Šå®‰è£…qwen3:30B")
        return
    
    # æ­¥éª¤3: æµ‹è¯•æ¨¡å‹ç”Ÿæˆ
    if not test_model_generation():
        print("\nâŒ æ¨¡å‹ç”Ÿæˆå¤±è´¥")
        return
    
    # æ­¥éª¤4: æµ‹è¯•ollamaå®¢æˆ·ç«¯
    if not test_ollama_client():
        print("\nâŒ ollamaå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¿œç¨‹qwen3:30Bæ¨¡å‹é…ç½®æˆåŠŸï¼")
    print("=" * 60)
    print("ç°åœ¨å¯ä»¥å¯åŠ¨é¡¹ç›®ä½¿ç”¨è¿œç¨‹å¤§æ¨¡å‹è¿›è¡Œä½œä¸šæ‰¹æ”¹äº†ã€‚")

if __name__ == "__main__":
    main()
