# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆHuggingFaceå®¢æˆ·ç«¯ - å·²éªŒè¯å¯ç”¨ï¼ˆå·²å¼ƒç”¨ï¼‰
è¿æ¥æœåŠ¡å™¨172.31.179.77:8007ï¼Œä½¿ç”¨æ­£ç¡®çš„APIæ ¼å¼
æ³¨æ„ï¼šæ­¤å®¢æˆ·ç«¯å·²è¢«qwen_vl_direct_serviceæ›¿ä»£ï¼Œç°åœ¨ç›´æ¥è°ƒç”¨LoRAè®­ç»ƒæ¨¡å‹
æ¨èä½¿ç”¨ï¼šapp/services/qwen_vl_direct_service.py
"""
import requests
import json
import sys
import os

# ä¿®å¤Windowsç¼–ç é—®é¢˜
if sys.platform.startswith('win'):
    os.environ['PYTHONIOENCODING'] = 'utf-8'

class HuggingFaceClient:
    def __init__(self):
        self.hf_url = "http://172.31.179.77:8007"
        self.ollama_url = "http://172.31.179.77:11434" 
        self.timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶
        
        print("[INFO] HuggingFaceå®¢æˆ·ç«¯å·²å°±ç»ªï¼ˆå·²å¼ƒç”¨ï¼Œæ¨èä½¿ç”¨qwen_vl_direct_serviceï¼‰")
        print(f"[INFO] å½“å‰æœåŠ¡: {self.hf_url} (ç°ä¸ºQwen2.5-VL-LoRA)")
        print(f"[INFO] å¤‡ç”¨æœåŠ¡: {self.ollama_url} (Ollama)")
        print("[WARN] æ­¤å®¢æˆ·ç«¯å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨app/services/qwen_vl_direct_service.py")
    
    def chat_completion(self, prompt: str, max_tokens: int = 200000):
        """æ™ºèƒ½èŠå¤©å®Œæˆ - ä¼˜å…ˆHuggingFaceï¼Œå¤‡ç”¨Ollama"""
        
        # ğŸ¥‡ ä¼˜å…ˆHuggingFace (å·²éªŒè¯å·¥ä½œ!)
        try:
            print("[INFO] è¿æ¥HuggingFace Qwen3-30B...")
            response = self._call_huggingface(prompt, max_tokens)
            if response.get("success"):
                print("[OK] HuggingFaceè°ƒç”¨æˆåŠŸ!")
                return response
            else:
                print(f"[WARNING] HuggingFaceé”™è¯¯: {response.get('error')}")
        except Exception as e:
            print(f"[ERROR] HuggingFaceå¼‚å¸¸: {e}")
        
        # ğŸ¥ˆ å¤‡ç”¨Ollama
        try:
            print("[INFO] åˆ‡æ¢åˆ°Ollamaå¤‡ç”¨æœåŠ¡...")
            response = self._call_ollama(prompt, max_tokens)
            if response.get("success"):
                print("[OK] Ollamaè°ƒç”¨æˆåŠŸ!")
                return response
        except Exception as e:
            print(f"[ERROR] Ollamaå¤±è´¥: {e}")
        
        return {
            "success": False,
            "error": "æ‰€æœ‰æœåŠ¡å‡ä¸å¯ç”¨",
            "response": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
        }
    
    def _call_huggingface(self, prompt: str, max_tokens: int):
        """è°ƒç”¨HuggingFaceæœåŠ¡ - å·²éªŒè¯çš„APIæ ¼å¼"""
        url = f"{self.hf_url}/api/v1/chat"
        
        # âœ… æ­£ç¡®çš„è¯·æ±‚æ ¼å¼ (å·²éªŒè¯)
        payload = {
            "query": prompt,  # æœåŠ¡å™¨æœŸæœ›çš„å­—æ®µå
            "max_new_tokens": max_tokens,
            "temperature": 0.7
        }
        
        print(f"[DEBUG] POST {url}")
        print(f"[DEBUG] Data: {json.dumps(payload, ensure_ascii=False)[:100]}...")
        
        response = requests.post(
            url,
            json=payload,
            timeout=self.timeout,
            headers={"Content-Type": "application/json"}
        )
        
        if response.status_code == 200:
            data = response.json()
            
            # æ£€æŸ¥æœåŠ¡å™¨é”™è¯¯
            if "error" in data:
                return {"success": False, "error": data["error"]}
            
            # âœ… æˆåŠŸå“åº”æ ¼å¼
            return {
                "success": True,
                "response": data.get("response", ""),
                "model_used": f"HuggingFace-{data.get('model', 'Qwen3-30B')}",
                "tokens_used": data.get("max_tokens_used", 0)
            }
        else:
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}"
            }
    
    def _call_ollama(self, prompt: str, max_tokens: int):
        """è°ƒç”¨Ollamaå¤‡ç”¨æœåŠ¡"""
        url = f"{self.ollama_url}/api/generate"
        
        payload = {
            "model": "qwen3:30B",
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_predict": max_tokens,
                "temperature": 0.7
            }
        }
        
        response = requests.post(url, json=payload, timeout=self.timeout)
        response.raise_for_status()
        
        data = response.json()
        return {
            "success": True,
            "response": data.get("response", ""),
            "model_used": "Ollama-Qwen3-30B",
            "tokens_used": len(data.get("response", "").split())
        }

# ğŸ§ª å®Œæ•´æµ‹è¯•
def comprehensive_test():
    """å®Œæ•´æµ‹è¯•HuggingFaceè¿æ¥"""
    print("ğŸš€ HuggingFaceæœåŠ¡å®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    client = HuggingFaceClient()
    
    # æµ‹è¯•å¤šä¸ªåœºæ™¯
    test_cases = [
        "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä½ è‡ªå·±",
        "è¯·å¸®æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—", 
        "Pythonä¸­å¦‚ä½•è¯»å–æ–‡ä»¶ï¼Ÿ",
        "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ"
    ]
    
    for i, prompt in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {prompt}")
        print("-" * 40)
        
        result = client.chat_completion(prompt, max_tokens=200)
        
        print(f"æˆåŠŸ: {result['success']}")
        print(f"æ¨¡å‹: {result.get('model_used', 'unknown')}")
        if result['success']:
            response = result.get('response', '')
            print(f"å›å¤: {response[:100]}{'...' if len(response) > 100 else ''}")
        else:
            print(f"é”™è¯¯: {result.get('error', 'unknown')}")
        
        print()
    
    print("ğŸ¯ æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    comprehensive_test()
