# 🚀 服务器端多模态AI配置指南

## 📋 **概述**
本指南帮助您在服务器端配置Qwen3:30B多模态API，替代传统OCR+批改方案，实现图片直接识别+批改功能。

## 🎯 **目标架构**
```
客户端图片 → 服务器Qwen3:30B → 完整批改结果
     ↓ (失败时)
   OCR备用方案 → 传统AI批改
```

## 📄 **API规范**

### **端点**: `POST /analyze`

### **请求格式**:
```json
{
  "image": "base64编码的图片数据",
  "prompt": "分析提示词",
  "max_tokens": 200000,
  "temperature": 0.1
}
```

### **响应格式**:
```json
{
  "success": true,
  "response": "AI生成的JSON结果字符串",
  "model_used": "qwen3:30B",
  "processing_time": 45.2,
  "tokens_used": 15000
}
```

### **期望的AI响应JSON结构**:
```json
{
  "questions": [
    {
      "question_number": "1",
      "question_text": "题目内容",
      "student_answer": "学生答案",
      "question_type": "计算题",
      "is_correct": false,
      "score": 0,
      "max_score": 5,
      "correct_answer": "正确答案",
      "explanation": "详细批改说明",
      "error_analysis": "错误分析",
      "knowledge_points": ["相关知识点"]
    }
  ],
  "overall_summary": {
    "total_score": 0,
    "total_possible": 5,
    "accuracy_rate": 0.0,
    "wrong_knowledge_points": ["计算能力"],
    "suggestions": ["建议重点复习基础计算"]
  }
}
```

## 🛠️ **服务器端实现要求**

### **1. 依赖包**
- FastAPI 或 Flask
- Transformers (HuggingFace)
- Pillow (图片处理)
- torch (PyTorch)

### **2. 关键功能**
- ✅ 接收base64图片数据
- ✅ 图片解码和预处理
- ✅ 调用Qwen3:30B多模态模型
- ✅ 返回结构化JSON结果
- ✅ 错误处理和超时管理

---

# 🎤 **Cursor助手提示词**

## **第一步：创建多模态API端点**

请帮我创建一个多模态AI分析API端点，要求如下：

**功能要求**：
1. **端点路径**: `POST /analyze`
2. **接收参数**: 
   - `image`: base64编码的图片
   - `prompt`: 分析提示词
   - `max_tokens`: 最大token数(默认200000)
   - `temperature`: 温度参数(默认0.1)

**处理流程**：
1. 解码base64图片数据
2. 将图片和提示词发送给Qwen3:30B模型
3. 模型应该能够：
   - 识别图片中的作业内容
   - 理解题目和学生答案
   - 进行详细批改和评分
   - 返回结构化的批改结果

**返回格式**：
```json
{
  "success": true,
  "response": "AI生成的批改结果(JSON字符串)",
  "model_used": "qwen3:30B", 
  "processing_time": 时间秒数,
  "tokens_used": token使用数量
}
```

**错误处理**：
- 图片解码失败
- 模型调用超时
- 返回格式错误

请使用当前项目的架构风格，确保与现有代码兼容。

---

## **第二步：优化提示词**

请帮我优化多模态模型的提示词，使其能够：

**核心功能**：
1. **精确识别**：准确识别手写和印刷体文字
2. **题目理解**：理解题目要求和解题思路
3. **答案分析**：分析学生答案的正确性
4. **详细批改**：提供具体的错误分析和改进建议
5. **知识点归纳**：识别涉及的数学知识点

**输出要求**：
- 必须返回有效的JSON格式
- 包含题目、答案、分数、解释等完整信息
- 特别注意数学计算的准确性
- 提供具体的错误修正建议

**示例场景**：
- 手写数学计算题
- 几何图形题
- 应用题（带图表）
- 混合题型

请生成一个详细的、结构化的提示词模板。

---

## **第三步：模型配置优化**

请帮我配置Qwen3:30B模型以获得最佳性能：

**性能要求**：
1. **响应时间**: 目标 < 2分钟
2. **准确性**: 数学计算准确率 > 95%
3. **稳定性**: 处理失败率 < 5%
4. **资源使用**: 合理的GPU内存使用

**配置参数**：
- `max_tokens`: 200000 (支持详细输出)
- `temperature`: 0.1 (确保一致性)
- 图片处理：最大分辨率、压缩比例
- 超时设置：请求超时、模型推理超时

**监控指标**：
- 请求响应时间
- 模型准确率
- 错误类型统计
- 资源使用情况

请提供具体的配置代码和监控方案。

---

## **第四步：测试验证方案**

请帮我创建测试方案来验证多模态AI的效果：

**测试内容**：
1. **功能测试**：API端点正常工作
2. **准确性测试**：与标准答案对比
3. **性能测试**：响应时间和并发处理
4. **边界测试**：模糊图片、复杂题目

**测试数据**：
- 不同类型的数学题目
- 不同质量的图片（清晰、模糊、倾斜）
- 不同难度级别
- 边界情况（空白、无法识别）

**评估标准**：
- 识别准确率
- 批改质量
- 响应时间
- 用户体验

请提供详细的测试代码和评估方法。

---

# 📋 **实施检查清单**

## **服务器端 (您需要完成)**
- [ ] 安装必要的依赖包
- [ ] 创建 `/analyze` 端点
- [ ] 配置Qwen3:30B多模态模型
- [ ] 实现图片处理和解码
- [ ] 优化提示词和参数
- [ ] 添加错误处理和日志
- [ ] 测试API端点功能

## **本地端 (已完成)**
- [x] 创建 `MultimodalAIService` 类
- [x] 修改上传路由优先级
- [x] 添加错误回退机制
- [x] 集成到现有工作流
- [x] 更新响应格式
- [x] 测试连接功能

## **集成测试 (双方配合)**
- [ ] 端到端连接测试
- [ ] 图片上传和处理验证
- [ ] 批改结果格式验证
- [ ] 性能基准测试
- [ ] 错误处理验证

---

# 🎯 **期望效果**

完成配置后，系统将实现：
- ✅ **99%图片直接处理**：无需OCR转换
- ✅ **95%+批改准确率**：基于视觉理解
- ✅ **2分钟内响应**：包含完整分析
- ✅ **智能错误恢复**：失败时自动回退
- ✅ **详细批改报告**：包含知识点分析

这将显著提升用户体验和批改质量！🚀
