#!/usr/bin/env python3
"""
ç»Ÿä¸€æ•°æ®è´¨é‡éªŒè¯è„šæœ¬
éªŒè¯æ”¶é›†çš„æ•°æ®æ˜¯å¦ç¬¦åˆè´¨é‡æ ‡å‡†
"""

import os
import sys
import pandas as pd
import json
import logging
from datetime import datetime
from pathlib import Path

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def validate_data_quality():
    """éªŒè¯æ•°æ®è´¨é‡"""
    logger.info("ğŸ” å¼€å§‹æ•°æ®è´¨é‡éªŒè¯...")

    try:
        base_dir = os.path.dirname(os.path.dirname(__file__))
        processed_dir = os.path.join(base_dir, "processed")
        
        validation_results = {
            "timestamp": datetime.now().isoformat(),
            "validation_summary": {
                "total_files_checked": 0,
                "total_records": 0,
                "data_quality_issues": 0,
                "overall_quality": "unknown"
            },
            "file_details": {},
            "quality_metrics": {},
            "recommendations": []
        }

        # æ£€æŸ¥å¤„ç†åçš„ç»Ÿä¸€æ•°æ®æ–‡ä»¶
        files_to_check = [
            ("knowledge_points_unified.csv", "çŸ¥è¯†ç‚¹"),
            ("questions_unified.csv", "é¢˜ç›®")
        ]

        total_records = 0
        total_issues = 0

        for filename, data_type in files_to_check:
            file_path = os.path.join(processed_dir, filename)
            
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path)
                    record_count = len(df)
                    total_records += record_count
                    
                    # æ£€æŸ¥æ•°æ®è´¨é‡
                    quality_issues = check_data_quality(df, data_type)
                    total_issues += len(quality_issues)
                    
                    validation_results["file_details"][filename] = {
                        "exists": True,
                        "record_count": record_count,
                        "columns": list(df.columns),
                        "quality_issues": quality_issues,
                        "data_types": {col: str(dtype) for col, dtype in df.dtypes.items()}
                    }
                    
                    validation_results["validation_summary"]["total_files_checked"] += 1
                    logger.info(f"âœ… {data_type}æ•°æ®: {record_count} æ¡è®°å½•, {len(quality_issues)} ä¸ªè´¨é‡é—®é¢˜")
                    
                except Exception as e:
                    validation_results["file_details"][filename] = {
                        "exists": True,
                        "error": str(e)
                    }
                    logger.error(f"âŒ è¯»å– {filename} å¤±è´¥: {e}")
            else:
                validation_results["file_details"][filename] = {"exists": False}
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")

        # æ›´æ–°æ±‡æ€»ä¿¡æ¯
        validation_results["validation_summary"]["total_records"] = total_records
        validation_results["validation_summary"]["data_quality_issues"] = total_issues
        
        # è®¡ç®—è´¨é‡ç­‰çº§
        if total_records == 0:
            quality_grade = "no_data"
        elif total_issues == 0:
            quality_grade = "excellent"
        elif total_issues / total_records < 0.05:
            quality_grade = "good"
        elif total_issues / total_records < 0.15:
            quality_grade = "fair"
        else:
            quality_grade = "poor"
            
        validation_results["validation_summary"]["overall_quality"] = quality_grade

        # ç”Ÿæˆè´¨é‡æŒ‡æ ‡
        validation_results["quality_metrics"] = generate_quality_metrics(validation_results)

        # ç”Ÿæˆå»ºè®®
        validation_results["recommendations"] = generate_recommendations(validation_results)

        # ä¿å­˜éªŒè¯æŠ¥å‘Š
        report_file = os.path.join(
            processed_dir,
            f'validation_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        )

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(validation_results, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        logger.info(f"ğŸ“Š è´¨é‡ç­‰çº§: {quality_grade}")
        logger.info(f"ğŸ“ˆ æ€»è®°å½•æ•°: {total_records}, è´¨é‡é—®é¢˜: {total_issues}")

        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False

def check_data_quality(df, data_type):
    """æ£€æŸ¥æ•°æ®æ¡†çš„è´¨é‡é—®é¢˜"""
    issues = []
    
    # æ£€æŸ¥ç©ºå€¼
    null_counts = df.isnull().sum()
    for col, null_count in null_counts.items():
        if null_count > 0:
            issues.append(f"{col}åˆ—æœ‰{null_count}ä¸ªç©ºå€¼")
    
    # æ£€æŸ¥é‡å¤è®°å½•
    duplicates = df.duplicated().sum()
    if duplicates > 0:
        issues.append(f"å‘ç°{duplicates}æ¡é‡å¤è®°å½•")
    
    # æ ¹æ®æ•°æ®ç±»å‹è¿›è¡Œç‰¹å®šæ£€æŸ¥
    if data_type == "çŸ¥è¯†ç‚¹":
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['subject', 'knowledge_point', 'description']
        for field in required_fields:
            if field not in df.columns:
                issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            elif df[field].isnull().any():
                issues.append(f"å¿…éœ€å­—æ®µ{field}åŒ…å«ç©ºå€¼")
    
    elif data_type == "é¢˜ç›®":
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ['subject', 'question', 'answer']
        for field in required_fields:
            if field not in df.columns:
                issues.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            elif df[field].isnull().any():
                issues.append(f"å¿…éœ€å­—æ®µ{field}åŒ…å«ç©ºå€¼")
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
    for col in df.select_dtypes(include=['object']).columns:
        avg_length = df[col].dropna().str.len().mean()
        if avg_length < 10:  # æ–‡æœ¬å¤ªçŸ­å¯èƒ½æ˜¯è´¨é‡é—®é¢˜
            issues.append(f"{col}åˆ—å¹³å‡é•¿åº¦è¿‡çŸ­({avg_length:.1f}å­—ç¬¦)")
    
    return issues

def generate_quality_metrics(validation_results):
    """ç”Ÿæˆè´¨é‡æŒ‡æ ‡"""
    metrics = {}
    
    total_files = validation_results["validation_summary"]["total_files_checked"]
    total_records = validation_results["validation_summary"]["total_records"]
    total_issues = validation_results["validation_summary"]["data_quality_issues"]
    
    if total_records > 0:
        metrics["data_completeness"] = (total_records - total_issues) / total_records * 100
        metrics["error_rate"] = total_issues / total_records * 100
    else:
        metrics["data_completeness"] = 0
        metrics["error_rate"] = 100
    
    metrics["file_coverage"] = total_files / 2 * 100  # æœŸæœ›2ä¸ªæ–‡ä»¶
    
    return metrics

def generate_recommendations(validation_results):
    """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
    recommendations = []
    
    quality = validation_results["validation_summary"]["overall_quality"]
    total_records = validation_results["validation_summary"]["total_records"]
    total_issues = validation_results["validation_summary"]["data_quality_issues"]
    
    if quality == "no_data":
        recommendations.append("æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†å’Œç»Ÿä¸€å¤„ç†")
    elif quality == "poor":
        recommendations.append("æ•°æ®è´¨é‡è¾ƒå·®ï¼Œå»ºè®®é‡æ–°æ”¶é›†æ•°æ®")
        recommendations.append("æ£€æŸ¥æ•°æ®ç”Ÿæˆå’Œå¤„ç†æµç¨‹")
    elif quality == "fair":
        recommendations.append("æ•°æ®è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®å¢å¼ºæ•°æ®è´¨é‡")
        recommendations.append("æ¸…ç†é‡å¤å’Œæ— æ•ˆæ•°æ®")
    elif quality == "good":
        recommendations.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥å¤„ç†")
    elif quality == "excellent":
        recommendations.append("æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒ")
    
    if total_records < 500:
        recommendations.append("æ•°æ®é‡ä¸è¶³ï¼Œå»ºè®®å¢åŠ æ›´å¤šæ•°æ®")
    
    if total_issues > 0:
        recommendations.append(f"å‘ç°{total_issues}ä¸ªè´¨é‡é—®é¢˜ï¼Œå»ºè®®è¿›è¡Œæ•°æ®æ¸…ç†")
    
    return recommendations

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ” å¯åŠ¨æ•°æ®è´¨é‡éªŒè¯...")
    
    success = validate_data_quality()
    
    if success:
        logger.info("âœ… æ•°æ®è´¨é‡éªŒè¯å®Œæˆ")
    else:
        logger.error("âŒ æ•°æ®è´¨é‡éªŒè¯å¤±è´¥")
    
    return success

if __name__ == "__main__":
    main()